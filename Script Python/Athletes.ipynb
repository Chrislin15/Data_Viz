{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bbcfa4b-cf1a-4554-b0b0-07e992117d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement des athlètes dont le nom commence par 'A'\n",
      "  - Récupération de la page 1 pour 'A'\n",
      "    Nombre d'athlètes trouvés sur cette page: 1216\n",
      "Traitement des athlètes dont le nom commence par 'B'\n",
      "  - Récupération de la page 1 pour 'B'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 380>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInformations sauvegardées pour \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_athletes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m athlètes dans \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 381\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Récupération de la page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m pour \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mletter\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# Récupérer les athlètes de la page actuelle\u001b[39;00m\n\u001b[1;32m--> 345\u001b[0m letter_athletes, next_page_url \u001b[38;5;241m=\u001b[39m \u001b[43mget_athletes_from_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Nombre d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mathlètes trouvés sur cette page: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(letter_athletes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    348\u001b[0m all_athletes\u001b[38;5;241m.\u001b[39mextend(letter_athletes)\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mget_athletes_from_page\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m    289\u001b[0m athletes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 291\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# Extraire les cartes d'athlètes\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py:75\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m'\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    524\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m: allow_redirects,\n\u001b[0;32m    527\u001b[0m }\n\u001b[0;32m    528\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 529\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    642\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    644\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 645\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    647\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    648\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 440\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    455\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproxy_pool\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#ATHLETES\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "\n",
    "pays_dict = {\n",
    "    'afghanistan': 'af',\n",
    "    'albania': 'al',\n",
    "    'algeria': 'dz',         \n",
    "    'argentina': 'ar',\n",
    "    'armenia': 'am',\n",
    "    'australia': 'au',\n",
    "    'australia / new zealand (australasia)': 'au/nz',\n",
    "    'austria': 'at',\n",
    "    'austria / united states of amerika': 'at/us',\n",
    "    'azerbaijan': 'az',\n",
    "    'bahamas': 'bs',\n",
    "    'bahrain': 'bh',\n",
    "    'barbados': 'bb',\n",
    "    'belarus': 'by',\n",
    "    'belgium': 'be',\n",
    "    'bermuda': 'bm',\n",
    "    'bohemia': 'cz',\n",
    "    'bohemia / great britain': 'cz/gb',\n",
    "    'botswana': 'bw',\n",
    "    'brazil': 'br',\n",
    "    'bulgaria': 'bg',\n",
    "    'burkina-faso': 'bf',\n",
    "    'burundi': 'bi',\n",
    "    'cameroon': 'cm',         \n",
    "    'canada': 'ca',\n",
    "    'cape verde': 'cv',\n",
    "    'chile': 'cl',\n",
    "    'china': 'cn',\n",
    "    'chinese taipei': 'tw',\n",
    "    'colombia': 'co',\n",
    "    'commonwealth of independent states': 'cis',\n",
    "    'costa rica': 'cr',\n",
    "    'cote divoire': 'ci',\n",
    "    'croatia': 'hr',\n",
    "    'cuba': 'cu',\n",
    "    'cyprus': 'cy',\n",
    "    'czech republic': 'cz',\n",
    "    'czechoslovakia': 'cs',\n",
    "    'denmark': 'dk',\n",
    "    'djibouti': 'dj',\n",
    "    'dominican': 'dm',\n",
    "    'dominican republic': 'do',\n",
    "    'ecuador': 'ec',\n",
    "    'egypt': 'eg',\n",
    "    'eritrea': 'er',\n",
    "    'estonia': 'ee',\n",
    "    'ethiopia': 'et',\n",
    "    'federal republic of germany': 'de',\n",
    "    'fiji': 'fj',\n",
    "    'finland': 'fi',\n",
    "    'france': 'fr',\n",
    "    'france / great britain': 'fr/gb',\n",
    "    'france / great britain / ireland': 'fr/gb/ie',\n",
    "    'gabon': 'ga',\n",
    "    'georgia': 'ge',\n",
    "    'german democratic republic': 'dd',\n",
    "    'germany': 'de',\n",
    "    'ghana': 'gh',\n",
    "    'great britain': 'gb',\n",
    "    'great britain / australia': 'gb/au',\n",
    "    'great britain / france / united states of america': 'gb/fr/us',\n",
    "    'great britain / ireland': 'gb/ie',\n",
    "    'great britain / ireland / germany': 'gb/ie/de',\n",
    "    'greece': 'gr',\n",
    "    'greece / belgium': 'gr/be',\n",
    "    'grenada': 'gd',\n",
    "    'guatemala': 'gt',\n",
    "    'guyana': 'gy',\n",
    "    'haiti': 'ht',\n",
    "    'hong kong': 'hk',\n",
    "    'hungary': 'hu',\n",
    "    'iceland': 'is',\n",
    "    'independent olympic participants': 'iop',\n",
    "    'india': 'in',\n",
    "    'individual neutral athletes': 'ina',\n",
    "    'individual olympic athletes': 'ioa',\n",
    "    'indonesia': 'id',\n",
    "    'iran': 'ir',\n",
    "    'iraq': 'iq',\n",
    "    'ireland': 'ie',\n",
    "    'israel': 'il',\n",
    "    'italy': 'it',\n",
    "    'jamaica': 'jm',\n",
    "    'japan': 'jp',\n",
    "    'japan / korea': 'jp/kr',\n",
    "    'jordan': 'jo',         \n",
    "    'kazakhstan': 'kz',\n",
    "    'kenya': 'ke',\n",
    "    'kosovo': 'xk',\n",
    "    'kuwait': 'kw',\n",
    "    'kyrgyzstan': 'kg',\n",
    "    'latvia': 'lv',\n",
    "    'lebanon': 'lb',\n",
    "    'liechtenstein': 'li',\n",
    "    'lithuania': 'lt',\n",
    "    'luxembourg': 'lu',       \n",
    "    'luxembourg / france': 'lu/fr',\n",
    "    'malaysia': 'my',\n",
    "    'mauritius': 'mu',\n",
    "    'mexico': 'mx',\n",
    "    'moldova': 'md',\n",
    "    'mongolia': 'mn',\n",
    "    'montenegro': 'me',\n",
    "    'morocco': 'ma',         \n",
    "    'mozambique': 'mz',\n",
    "    'namibia': 'na',\n",
    "    'netherlands': 'nl',\n",
    "    'netherlands / france': 'nl/fr',\n",
    "    'netherlands antilles': 'an',\n",
    "    'new zealand': 'nz',\n",
    "    'niger': 'ne',\n",
    "    'nigeria': 'ng',\n",
    "    'north korea': 'kp',     \n",
    "    'north-macedonia': 'mk',\n",
    "    'norway': 'no',\n",
    "    'pakistan': 'pk',\n",
    "    'panama': 'pa',\n",
    "    'paraguay': 'py',\n",
    "    'peru': 'pe',\n",
    "    'philippines': 'ph',\n",
    "    'poland': 'pl',\n",
    "    'portugal': 'pt',\n",
    "    'puerto rico': 'pr',     \n",
    "    'qatar': 'qa',        \n",
    "    'refugee olympic team': 'rot',\n",
    "    'romania': 'ro',\n",
    "    'russia': 'ru',\n",
    "    'russian olympic committee': 'roc',\n",
    "    'saint lucia': 'lc',     \n",
    "    'samoa': 'ws',\n",
    "    'san marino': 'sm',   \n",
    "    'saudi arabia': 'sa',     \n",
    "    'senegal': 'sn',\n",
    "    'serbia': 'rs',\n",
    "    'serbia montenegro': 'cs',\n",
    "    'singapore': 'sg',\n",
    "    'slovakia': 'sk',\n",
    "    'slovenia': 'si',\n",
    "    'smyrna': 'tr',\n",
    "    'south africa': 'za',\n",
    "    'south korea': 'kr',\n",
    "    'soviet union': 'su',\n",
    "    'spain': 'es',\n",
    "    'sri lanka': 'lk',\n",
    "    'sudan': 'sd',\n",
    "    'suriname': 'sr',\n",
    "    'sweden': 'se',\n",
    "    'sweden / denmark': 'se/dk',\n",
    "    'switzerland': 'ch',\n",
    "    'syria': 'sy',           \n",
    "    'tajikistan': 'tj',      \n",
    "    'tanzania': 'tz',\n",
    "    'thailand': 'th',\n",
    "    'thessalonika': 'gr',\n",
    "    'togo': 'tg',\n",
    "    'tonga': 'to',\n",
    "    'trinidad & tobago': 'tt',\n",
    "    'tunisia': 'tn',         \n",
    "    'turkey': 'tr',\n",
    "    'turkmenistan': 'tm',\n",
    "    'uganda': 'ug',          \n",
    "    'ukraine': 'ua',\n",
    "    'united arab emirates': 'ae', \n",
    "    'united states of america': 'us',\n",
    "    'united states of america / cuba': 'us/cu',\n",
    "    'united states of america / france': 'us/fr',\n",
    "    'united states of america / germany': 'us/de',\n",
    "    'united states of america / great britain': 'us/gb',\n",
    "    'united states of america / mexico': 'us/mx',\n",
    "    'uruguay': 'uy',       \n",
    "    'uzbekistan': 'uz',      \n",
    "    'venezuela': 've',\n",
    "    'vietnam': 'vn',\n",
    "    'virgin islands': 'vi',\n",
    "    'west indies federation': 'wif',\n",
    "    'yugoslavia': 'yu',\n",
    "    'zambia': 'zm',\n",
    "    'zimbabwe': 'zw'\n",
    "}\n",
    "\n",
    "# Création d'un dictionnaire inversé pour recherche par code\n",
    "codes_pays_dict = {v: k for k, v in pays_dict.items()}\n",
    "\n",
    "def extract_basic_info(person, pays_dict):\n",
    "    \"\"\"Extrait les informations de base d'un élément HTML d'athlète\"\"\"\n",
    "\n",
    "    link = person.get('href')\n",
    "    athlete_id = None\n",
    "    if link:\n",
    "        id_match = re.search(r'/olympic-athlete/[^/]+/(\\d+)', link)\n",
    "        if id_match:\n",
    "            athlete_id = id_match.group(1)\n",
    "    \n",
    "    # Extraction du prénom et du nom\n",
    "    prenom_div = person.select_one('div.vn')\n",
    "    nom_div = person.select_one('div.n')\n",
    "    prenom = prenom_div.get_text(strip=True) if prenom_div else \"\"\n",
    "    nom = nom_div.get_text(strip=True) if nom_div else \"\"\n",
    "    \n",
    "    # Extraction du pays\n",
    "    flag_img = person.select_one('img[src*=\"flagge\"]')\n",
    "    pays = flag_img.get('alt') if flag_img and flag_img.get('alt') else \"\"\n",
    "    \n",
    "    if not pays and flag_img and flag_img.get('src'):\n",
    "        src = flag_img.get('src')\n",
    "        pays_code = src.split('/')[-1].split('.')[0]\n",
    "        pays = codes_pays_dict.get(pays_code.lower(), pays_code)\n",
    "    \n",
    "    # Extraction du sexe\n",
    "    sexe = \"\"\n",
    "    if person.select_one('svg.female'):\n",
    "        sexe = 'female'\n",
    "    elif person.select_one('svg.male'):\n",
    "        sexe = 'male'\n",
    "    \n",
    "    user = {\n",
    "        'id': athlete_id,\n",
    "        'prenom': prenom,\n",
    "        'nom': nom,\n",
    "        'pays': pays,\n",
    "        'sexe': sexe,\n",
    "        'profile_url': f\"https://olympics-statistics.com{link}\" if link else \"\",\n",
    "        'medailles': {\n",
    "            'nombre': 0,\n",
    "            'types': [],\n",
    "            'sport': \"\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return user\n",
    "\n",
    "\n",
    "def extract_medal_info(profile_url):\n",
    "    \"\"\"Extrait les informations de médailles depuis l'URL du profil d'un athlète\"\"\"\n",
    "    try:\n",
    "        response = requests.get(profile_url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "\n",
    "        nombre_medailles = 0\n",
    "        types_medailles = []\n",
    "        sport = \"\"\n",
    "        \n",
    "\n",
    "        medals = soup.select('.deck .medaille.visible')\n",
    "        nombre_medailles = len(medals)\n",
    "        \n",
    "        for medal in medals:\n",
    "\n",
    "            medal_div = medal.select_one('.the-medal')\n",
    "            if medal_div and medal_div.has_attr('data-medal'):\n",
    "                code = medal_div['data-medal']\n",
    "                if code == '1':\n",
    "                    types_medailles.append(\"or\")\n",
    "                elif code == '2':\n",
    "                    types_medailles.append(\"argent\")\n",
    "                elif code == '3':\n",
    "                    types_medailles.append(\"bronze\")\n",
    "            \n",
    "            \n",
    "            sport_div = medal.select_one('.m-sport')\n",
    "            if sport_div:\n",
    "                sport = sport_div.text.strip()\n",
    "        \n",
    "        return {\n",
    "            'nombre': nombre_medailles,\n",
    "            'types': types_medailles,\n",
    "            'sport': sport\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'extraction des médailles pour {profile_url}: {str(e)}\")\n",
    "        return {\n",
    "            'nombre': 0,\n",
    "            'types': [],\n",
    "            'sport': \"\"\n",
    "        }\n",
    "\n",
    "def get_athletes_from_page(url):\n",
    "\n",
    "    athletes = []\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Extraire les cartes d'athlètes\n",
    "        athletes_links = soup.select('a.card.athlet.visible')\n",
    "        \n",
    "        for athlete_link in athletes_links:\n",
    "            # Extraire les informations de base\n",
    "            athlete = extract_basic_info(athlete_link, pays_dict)\n",
    "            athletes.append(athlete)\n",
    "        \n",
    "\n",
    "        pagination = soup.select('a.page-link')\n",
    "        next_page_url = None\n",
    "        \n",
    "        for page_link in pagination:\n",
    " \n",
    "            if page_link.text.strip() == '»' or page_link.text.strip().isdigit():\n",
    "                href = page_link.get('href')\n",
    "                if href and not href.startswith('http'):\n",
    "                    next_page_url = f\"https://olympics-statistics.com{href}\"\n",
    "                    break\n",
    "        \n",
    "        return athletes, next_page_url\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la récupération des athlètes depuis {url}: {str(e)}\")\n",
    "        return [], None\n",
    "\n",
    "def main():\n",
    "\n",
    "    letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \n",
    "              'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'special']\n",
    "    \n",
    "\n",
    "    all_athletes = []\n",
    "    \n",
    "    # Parcourir chaque lettre\n",
    "    for letter in letters:\n",
    "        print(f\"Traitement des athlètes dont le nom commence par '{letter.upper()}'\")\n",
    "        \n",
    "\n",
    "        if letter == 'special':\n",
    "            current_url = f\"https://olympics-statistics.com/olympic-athletes/{letter}\"\n",
    "        else:\n",
    "            current_url = f\"https://olympics-statistics.com/olympic-athletes/{letter}\"\n",
    "        \n",
    "        page_number = 1\n",
    "        \n",
    "        # Parcourir toutes les pages pour cette lettre\n",
    "        while current_url:\n",
    "            print(f\"  - Récupération de la page {page_number} pour '{letter.upper()}'\")\n",
    "            \n",
    "            # Récupérer les athlètes de la page actuelle\n",
    "            letter_athletes, next_page_url = get_athletes_from_page(current_url)\n",
    "            \n",
    "            print(f\"    Nombre d'athlètes trouvés sur cette page: {len(letter_athletes)}\")\n",
    "            all_athletes.extend(letter_athletes)\n",
    "            current_url = next_page_url\n",
    "            page_number += 1\n",
    "            time.sleep(1)\n",
    "    \n",
    "    print(f\"Total d'athlètes trouvés: {len(all_athletes)}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    for i, athlete in enumerate(all_athletes):\n",
    "        if i % 10 == 0:  # Afficher la progression tous les 10 athlètes\n",
    "            print(f\"Traitement des médailles {i}/{len(all_athletes)}\")\n",
    "        \n",
    "        if athlete['profile_url']:\n",
    "           \n",
    "            medals_info = extract_medal_info(athlete['profile_url'])\n",
    "            athlete['medailles'] = medals_info\n",
    "            \n",
    "            \n",
    "            time.sleep(0.5)\n",
    "    \n",
    "\n",
    "    output_file = \"olympic_athletes_complet.json\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_athletes, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"Informations sauvegardées pour {len(all_athletes)} athlètes dans {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e62e89bb-44db-4a44-a856-591bccf74966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données chargées : 31843 athlètes trouvés\n",
      "\n",
      "Aperçu avant nettoyage:\n",
      "      id     prenom       nom                      pays    sexe  \\\n",
      "0  25024   Jennifer      Azzi  united states of america  female   \n",
      "1  31553       Sera     Azuma                     japan  female   \n",
      "2  27117  Okechukwu  Azubuike                   nigeria    male   \n",
      "3  32171   Jeremiah       Azu             great britain    male   \n",
      "4  27116    Jeremie      Azou                    france    male   \n",
      "\n",
      "                                         profile_url  \\\n",
      "0  https://olympics-statistics.com/olympic-athlet...   \n",
      "1  https://olympics-statistics.com/olympic-athlet...   \n",
      "2  https://olympics-statistics.com/olympic-athlet...   \n",
      "3  https://olympics-statistics.com/olympic-athlet...   \n",
      "4  https://olympics-statistics.com/olympic-athlet...   \n",
      "\n",
      "                                           medailles  \n",
      "0  {'nombre': 1, 'types': ['or'], 'sport': 'Baske...  \n",
      "1  {'nombre': 1, 'types': ['bronze'], 'sport': 'F...  \n",
      "2  {'nombre': 1, 'types': ['bronze'], 'sport': 'F...  \n",
      "3  {'nombre': 1, 'types': ['bronze'], 'sport': 'A...  \n",
      "4  {'nombre': 1, 'types': ['or'], 'sport': 'Rowing'}  \n",
      "Colonnes: ['id', 'prenom', 'nom', 'pays', 'sexe', 'profile_url', 'medailles']\n",
      "Données nettoyées enregistrées au format JSON dans 'athletes_clean.json'\n",
      "Nombre d'athlètes enregistrés: 31843\n",
      "\n",
      "Aperçu du premier athlète au format JSON:\n",
      "{\n",
      "  \"id\": \"25024\",\n",
      "  \"prenom\": \"Jennifer\",\n",
      "  \"nom\": \"Azzi\",\n",
      "  \"pays\": \"united states of america\",\n",
      "  \"sexe\": \"female\",\n",
      "  \"profile_url\": \"https://olympics-statistics.com/olympic-athlete/Jennifer-Azzi/25024\",\n",
      "  \"or\": 1,\n",
      "  \"argent\": 0,\n",
      "  \"bronze\": 0,\n",
      "  \"sport\": \"Basketball\",\n",
      "  \"nom_complet\": \"Jennifer Azzi\"\n",
      "}\n",
      "\n",
      "Données nettoyées sauvegardées dans athletesjsd\n",
      "\n",
      "Aperçu après nettoyage:\n",
      "      id     prenom       nom                      pays    sexe  \\\n",
      "0  25024   Jennifer      Azzi  united states of america  female   \n",
      "1  31553       Sera     Azuma                     japan  female   \n",
      "2  27117  Okechukwu  Azubuike                   nigeria    male   \n",
      "3  32171   Jeremiah       Azu             great britain    male   \n",
      "4  27116    Jeremie      Azou                    france    male   \n",
      "\n",
      "                                         profile_url  or  argent  bronze  \\\n",
      "0  https://olympics-statistics.com/olympic-athlet...   1       0       0   \n",
      "1  https://olympics-statistics.com/olympic-athlet...   0       0       1   \n",
      "2  https://olympics-statistics.com/olympic-athlet...   0       0       1   \n",
      "3  https://olympics-statistics.com/olympic-athlet...   0       0       1   \n",
      "4  https://olympics-statistics.com/olympic-athlet...   1       0       0   \n",
      "\n",
      "        sport         nom_complet  \n",
      "0  Basketball       Jennifer Azzi  \n",
      "1     Fencing          Sera Azuma  \n",
      "2    Football  Okechukwu Azubuike  \n",
      "3   Athletics        Jeremiah Azu  \n",
      "4      Rowing        Jeremie Azou  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    with open('olympic_athletes_complet.json', 'r', encoding='utf-8') as f:\n",
    "        athletes = json.load(f)\n",
    "    print(f\"Données chargées : {len(athletes)} athlètes trouvés\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Fichier athletes.json introuvable.\")\n",
    "    athletes = []\n",
    "\n",
    "df = pd.DataFrame(athletes)\n",
    "print(f\"Aperçu initial - Colonnes: {df.columns.tolist()}\")\n",
    "\n",
    "def nettoyer_data():\n",
    "    if len(df) == 0:\n",
    "        return df\n",
    "    \n",
    "    # Extraction des médailles et du sport\n",
    "    df['or'] = df['medailles'].apply(lambda x: x.get('types', []).count('or') if isinstance(x, dict) else 0)\n",
    "    df['argent'] = df['medailles'].apply(lambda x: x.get('types', []).count('argent') if isinstance(x, dict) else 0)\n",
    "    df['bronze'] = df['medailles'].apply(lambda x: x.get('types', []).count('bronze') if isinstance(x, dict) else 0)\n",
    "    df['sport'] = df['medailles'].apply(lambda x: x.get('sport', \"\") if isinstance(x, dict) else \"\")\n",
    "    \n",
    "    # Nettoyage des données\n",
    "    df['prenom'] = df['prenom'].fillna('')\n",
    "    df['nom'] = df['nom'].fillna('')\n",
    "    df['pays'] = df['pays'].fillna('Inconnu')\n",
    "    df['nom_complet'] = df['prenom'] + ' ' + df['nom']\n",
    "    \n",
    "\n",
    "    pays_courts = df[df['pays'].str.len() == 2]['pays'].unique()\n",
    "    if len(pays_courts) > 0:\n",
    "        print(f\"Codes pays courts détectés: {', '.join(pays_courts)}\")\n",
    "    \n",
    "\n",
    "    df_clean = df.drop(columns=['medailles'])\n",
    "    athletes_clean = df_clean.to_dict(orient='records')\n",
    "    \n",
    "    with open('athletes_complet_clean.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(athletes_clean, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"Données de {len(athletes_clean)} athlètes sauvegardées dans athletes_complet_clean.json\")\n",
    "    return df_clean\n",
    "\n",
    "df_clean = nettoyer_data()\n",
    "print(\"\\nAperçu après nettoyage:\")\n",
    "print(df_clean.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
